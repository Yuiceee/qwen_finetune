# Scripts ç›®å½•è¯´æ˜

æœ¬ç›®å½•åŒ…å«é‚®ä»¶äº‹ä»¶æå–ä»»åŠ¡çš„æ‰€æœ‰è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
scripts/
â”œâ”€â”€ README.md                        # æœ¬æ–‡ä»¶
â”œâ”€â”€ 01_process_enron_csv.py         # æ•°æ®é¢„å¤„ç†ï¼šä»CSVæå–é‚®ä»¶
â”œâ”€â”€ 02_generate_annotations.py      # ä½¿ç”¨LLMç”Ÿæˆæ ‡æ³¨æ•°æ®
â”œâ”€â”€ 03_split_dataset.py             # æ‹†åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
â”œâ”€â”€ clean_and_standardize_data.py   # æ•°æ®æ¸…ç†ï¼šç»Ÿä¸€schemaã€ä¿®å¤JSON
â”œâ”€â”€ standardize_time_fields_v2.py   # æ—¶é—´å­—æ®µæ ‡å‡†åŒ–
â”œâ”€â”€ fix_annotations_with_llm.py     # LLMè¾…åŠ©å®¡æ ¸å’Œä¿®æ­£æ ‡æ³¨ â­ NEW
â”œâ”€â”€ check_data_quality.py           # æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·
â”œâ”€â”€ analyze_errors.py               # è¯¦ç»†é”™è¯¯åˆ†æ
â”œâ”€â”€ analyze_errors_simple.py        # ç®€åŒ–ç‰ˆé”™è¯¯åˆ†æ
â”œâ”€â”€ train_lora.py                   # LoRAå¾®è°ƒè®­ç»ƒè„šæœ¬
â”œâ”€â”€ evaluate_models.py              # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ inference.py                    # å‘½ä»¤è¡Œæ¨ç†è„šæœ¬
â””â”€â”€ inference.ipynb                 # Jupyteræ¨ç†notebook
```

## ğŸ”„ æ•°æ®å¤„ç†æµç¨‹

### é˜¶æ®µ1: åŸå§‹æ•°æ®å‡†å¤‡
```bash
# 1. ä»CSVæå–é‚®ä»¶ï¼ˆé‡‡æ ·ï¼‰
uv run python scripts/01_process_enron_csv.py \
    --input data/emails.csv \
    --output data/raw/enron_sampled.jsonl \
    --sample_size 2000

# 2. ä½¿ç”¨LLMç”Ÿæˆæ ‡æ³¨
uv run python scripts/02_generate_annotations.py \
    --api_key "YOUR_API_KEY" \
    --base_url "API_BASE_URL" \
    --model "MODEL_NAME" \
    --template data/raw/annotation_template.json \
    --output data/raw/train_data_all.jsonl

# 3. æ‹†åˆ†æ•°æ®é›†
uv run python scripts/03_split_dataset.py \
    --input data/raw/train_data_all.jsonl \
    --output_dir data/processed
```

**è¾“å‡ºï¼š** `data/processed/{train,valid,test}.jsonl` (1860æ ·æœ¬)

---

### é˜¶æ®µ2: æ•°æ®æ¸…ç† âœ… (å·²å®Œæˆ)
```bash
# 4. æ¸…ç†JSONæ ¼å¼é”™è¯¯ï¼Œç»Ÿä¸€schema
uv run python scripts/clean_and_standardize_data.py
```

**æ•ˆæœï¼š**
- âŒ ç§»é™¤163ä¸ªJSONæ ¼å¼é”™è¯¯çš„æ ·æœ¬
- âœ… ç»Ÿä¸€ä¸ºæ ¸å¿ƒ6å­—æ®µï¼ševent_type, title, time, location, participants, organizer
- âœ… ç§»é™¤80+ä¸ªå†—ä½™å­—æ®µ

**è¾“å‡ºï¼š** `data/cleaned/{train,valid,test}.jsonl` (1697æ ·æœ¬)

---

### é˜¶æ®µ3: æ—¶é—´å­—æ®µæ ‡å‡†åŒ– âœ… (å·²å®Œæˆ)
```bash
# 5. æ ‡å‡†åŒ–æ—¶é—´å­—æ®µæ ¼å¼
uv run python scripts/standardize_time_fields_v2.py --execute --min_confidence=medium
```

**æ•ˆæœï¼š**
- âœ… 100%é‚®ä»¶æˆåŠŸæå–å¹´ä»½
- âœ… 80%çš„timeå­—æ®µæ ‡å‡†åŒ–ä¸º `YYYY-MM-DD` æˆ– `YYYY-MM-DD HH:MM`
- âœ… ä¿®å¤äº†å¹´ä»½é”™è¯¯é—®é¢˜ï¼ˆ"Nov. 7" â†’ "2001-11-07" è€Œé "2026-11-07"ï¼‰

**è¾“å‡ºï¼š** `data/standardized/{train,valid,test}.jsonl` (1367æ ·æœ¬)

---

### é˜¶æ®µ4: LLMè¾…åŠ©å®¡æ ¸æ ‡æ³¨ â­ (æ–°å¢)

**èƒŒæ™¯ï¼š** V2è®­ç»ƒåå‘ç°participants (42.3%)å’Œtime (51.1%)å­—æ®µå‡†ç¡®ç‡ä»ç„¶è¾ƒä½ï¼Œéœ€è¦ä½¿ç”¨LLMå®¡æ ¸å’Œæ”¹è¿›æ ‡æ³¨è´¨é‡ã€‚

```bash
# 6a. æµ‹è¯•å®¡æ ¸ï¼ˆå¤„ç†5ä¸ªæ ·æœ¬ï¼‰
export DEEPSEEK_API_KEY='your-api-key'
bash run_fix_annotations_test.sh

# 6b. å®Œæ•´å®¡æ ¸ï¼ˆå¤„ç†æ‰€æœ‰æ ·æœ¬ï¼‰
export DEEPSEEK_API_KEY='your-api-key'
bash run_fix_annotations.sh
```

**æˆ–æ‰‹åŠ¨è¿è¡Œï¼š**

```bash

# å®¡æ ¸æ‰€æœ‰æ ·æœ¬
uv run python scripts/fix_annotations_with_llm.py \
    --input data/standardized/valid.jsonl \
    --output data/reviewed/valid.jsonl \
    --api_key "$DEEPSEEK_API_KEY"
```

**æ•ˆæœï¼š**
- ğŸ¯ é‡ç‚¹æ”¹è¿›participantså’Œtimeå­—æ®µ
- ğŸ“Š ç”Ÿæˆè¯¦ç»†çš„å®¡æ ¸æŠ¥å‘Šï¼ŒåŒ…å«æ”¹è¿›å‰åå¯¹æ¯”
- ğŸ’° æˆæœ¬å¯æ§ï¼ˆèšç„¦æ¨¡å¼åªå¤„ç†é”™è¯¯æ ·æœ¬ï¼‰

**è¾“å‡ºï¼š** `data/reviewed/{train,valid,test}.jsonl` + å®¡æ ¸æŠ¥å‘Š

---

## ğŸš€ è®­ç»ƒæ¨¡å‹

### ä½¿ç”¨æ¸…ç†åçš„æ•°æ®è®­ç»ƒLoRA

```bash
# åŸºç¡€è®­ç»ƒï¼ˆæ¨èé…ç½®ï¼‰
uv run python scripts/train_lora.py

# è‡ªå®šä¹‰å‚æ•°
uv run python scripts/train_lora.py \
    --train_data data/standardized/train.jsonl \
    --eval_data data/standardized/valid.jsonl \
    --output_dir outputs/lora_model_v2 \
    --num_epochs 5 \
    --learning_rate 1e-4 \
    --warmup_ratio 0.1 \
    --early_stopping \
    --early_stopping_patience 5
```

### è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--train_data` | `data/standardized/train.jsonl` | è®­ç»ƒæ•°æ®ï¼ˆ1092æ ·æœ¬ï¼‰|
| `--eval_data` | `data/standardized/valid.jsonl` | éªŒè¯æ•°æ®ï¼ˆ138æ ·æœ¬ï¼‰|
| `--output_dir` | `outputs/lora_model_v2` | è¾“å‡ºç›®å½• |
| `--num_epochs` | `5` | è®­ç»ƒè½®æ•° |
| `--learning_rate` | `1e-4` | å­¦ä¹ ç‡ï¼ˆé™ä½ä»¥æé«˜ç¨³å®šæ€§ï¼‰|
| `--warmup_ratio` | `0.1` | å‰10%æ­¥æ•°ç”¨äºwarmup |
| `--early_stopping` | `True` | å¯ç”¨æ—©åœï¼ˆé»˜è®¤å¼€å¯ï¼‰|
| `--early_stopping_patience` | `5` | 5ä¸ªevalæ­¥éª¤æ— æ”¹è¿›åˆ™åœæ­¢ |

### âš ï¸ V1 vs V2 è®­ç»ƒå·®å¼‚

**V1è®­ç»ƒï¼ˆæ—§æ•°æ®ï¼‰ï¼š**
- æ•°æ®ï¼š`data/processed/` (1488æ ·æœ¬)
- é—®é¢˜ï¼š163ä¸ªJSONé”™è¯¯ï¼Œ80+å†—ä½™å­—æ®µï¼Œtimeæ ¼å¼æ··ä¹±
- ç»“æœï¼šå¹³å‡å­—æ®µå‡†ç¡®ç‡ 50%ï¼Œtimeå‡†ç¡®ç‡ 33%

**V2è®­ç»ƒï¼ˆæ–°æ•°æ®ï¼Œæ¨èï¼‰ï¼š**
- æ•°æ®ï¼š`data/standardized/` (1367æ ·æœ¬)
- æ”¹è¿›ï¼šé«˜è´¨é‡æ•°æ®ï¼Œç»Ÿä¸€schemaï¼Œtimeæ ‡å‡†åŒ–
- é¢„æœŸï¼šå¹³å‡å­—æ®µå‡†ç¡®ç‡ 70%+ï¼Œtimeå‡†ç¡®ç‡ 65%+

---

## ğŸ“Š è¯„ä¼°å’Œæ¨ç†

### è¯„ä¼°æ¨¡å‹
```bash
# å¯¹æ¯”åŸºç¡€æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹
uv run python scripts/evaluate_models.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --lora_model outputs/lora_model_v2/final_model \
    --test_file data/standardized/test.jsonl \
    --output outputs/evaluation_v2.json
```

### å‘½ä»¤è¡Œæ¨ç†
```bash
# å•æ ·æœ¬æ¨ç†
uv run python scripts/inference.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --lora_model outputs/lora_model_v2/final_model \
    --interactive

# æ‰¹é‡æ¨ç†
uv run python scripts/inference.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --lora_model outputs/lora_model_v2/final_model \
    --test_file data/standardized/test.jsonl \
    --max_samples 10
```

### Jupyter Notebookæ¨ç†
```bash
jupyter notebook scripts/inference.ipynb
```

---

## ğŸ› ï¸ å·¥å…·è„šæœ¬

### æ•°æ®è´¨é‡æ£€æŸ¥
```bash
# æ£€æŸ¥æ•°æ®é›†çš„è´¨é‡é—®é¢˜
uv run python scripts/check_data_quality.py
```

è¾“å‡ºæŠ¥å‘Šï¼š
- JSONæ ¼å¼é”™è¯¯ç»Ÿè®¡
- å­—æ®µä¸€è‡´æ€§åˆ†æ
- timeå­—æ®µæ ¼å¼åˆ†å¸ƒ
- è¾“å…¥é•¿åº¦åˆ†å¸ƒ

---

## ğŸ“ˆ é¢„æœŸæ”¹è¿›

ä½¿ç”¨æ¸…ç†åçš„æ•°æ®é‡æ–°è®­ç»ƒï¼Œé¢„æœŸæ•ˆæœï¼š

| æŒ‡æ ‡ | V1 (æ—§æ•°æ®) | V2 (æ–°æ•°æ®) | æ”¹è¿› |
|------|-------------|-------------|------|
| JSONæ ¼å¼æ­£ç¡®ç‡ | 95.7% | 98%+ | +2.3% |
| å¹³å‡å­—æ®µå‡†ç¡®ç‡ | 49.6% | 70%+ | +20% |
| timeå­—æ®µå‡†ç¡®ç‡ | 33.3% | 65%+ | +32% |
| event_typeå‡†ç¡®ç‡ | 64.5% | 75%+ | +10% |

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. âœ… **æ•°æ®å·²æ¸…ç†** - data/standardized/ ç›®å½• (1367æ ·æœ¬)
2. âœ… **V2è®­ç»ƒå®Œæˆ** - å¹³å‡å‡†ç¡®ç‡55.96%ï¼Œå‘ç°participantså’Œtimeå­—æ®µè¾ƒå¼±
3. â³ **LLMå®¡æ ¸æ ‡æ³¨** - ä½¿ç”¨DeepSeek APIæ”¹è¿›æ ‡æ³¨è´¨é‡
   ```bash
   export DEEPSEEK_API_KEY='your-key'
   bash run_fix_annotations_test.sh  # å…ˆæµ‹è¯•5ä¸ªæ ·æœ¬
   bash run_fix_annotations.sh       # å®Œæ•´å®¡æ ¸
   ```
4. â³ **V3è®­ç»ƒ** - ä½¿ç”¨å®¡æ ¸åçš„æ•°æ®é‡æ–°è®­ç»ƒ
5. â“ **è€ƒè™‘DPO** - å¦‚æœå‡†ç¡®ç‡è¾¾åˆ°70%+ä¸”ä¸»è¦é—®é¢˜æ˜¯æ ¼å¼è§„èŒƒæ€§

---

## ğŸ“ æ³¨æ„äº‹é¡¹

- æ‰€æœ‰è„šæœ¬ä½¿ç”¨ `uv run` æ‰§è¡Œï¼Œç¡®ä¿ä¾èµ–éš”ç¦»
- è®­ç»ƒéœ€è¦GPUï¼ˆæ¨èA100æˆ–ä»¥ä¸Šï¼‰
- SwanLabç”¨äºå®éªŒè·Ÿè¸ªï¼Œä¼šè‡ªåŠ¨è®°å½•æ‰€æœ‰æŒ‡æ ‡
- ä½¿ç”¨early stoppingé¿å…è¿‡æ‹Ÿåˆ
- æ—§ç‰ˆæœ¬è„šæœ¬å·²åˆ é™¤ï¼ˆstandardize_time_fields.py, comparison_analysis.pyï¼‰
